{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ok-yuto/CA_Tech_Lounge/blob/main/ca_tech_lounge_task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Gjd625kCU4qf",
        "outputId": "f6bdf428-4dda-43b8-9a14-5a93aa217858"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-58ca1cc84e3c>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Read Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mcovtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_covtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_covtype.py\u001b[0m in \u001b[0;36mfetch_covtype\u001b[0;34m(data_home, download_if_missing, random_state, shuffle, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading {ARCHIVE.url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0marchive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARCHIVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mXy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         rows = list(\n\u001b[0;32m-> 2160\u001b[0;31m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0m\u001b[1;32m   2161\u001b[0m                   for (i, conv) in enumerate(converters)]))\n\u001b[1;32m   2162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         rows = list(\n\u001b[0;32m-> 2160\u001b[0;31m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0m\u001b[1;32m   2161\u001b[0m                   for (i, conv) in enumerate(converters)]))\n\u001b[1;32m   2162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         rows = list(\n\u001b[0;32m-> 2160\u001b[0;31m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0m\u001b[1;32m   2161\u001b[0m                   for (i, conv) in enumerate(converters)]))\n\u001b[1;32m   2162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold, StratifiedKFold, RepeatedStratifiedKFold, GroupKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score,  precision_recall_curve, auc, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.manifold import TSNE, MDS\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# import pandas_profiling as pdp\n",
        "# from mlxtend.plotting import plot_decision_regions\n",
        "# !pip install optuna\n",
        "# import optuna\n",
        "# from optuna.integration import lightgbm as lgb\n",
        "import functools\n",
        "\n",
        "\n",
        "def objective_svc(X_train_std, X_test_std, y_train, y_test, trial):\n",
        "    #目的関数\n",
        "    params = {\n",
        "        'kernel': trial.suggest_categorical('kernel', ['linear','rbf','sigmoid']),\n",
        "        'C': trial.suggest_loguniform('C', 1e+0, 1e+2/2),\n",
        "        'gamma': trial.suggest_loguniform('gamma', 1e-3, 3.0),\n",
        "    }\n",
        "    mdl = svm.SVC(**params)\n",
        "    mdl.fit(X_train_std, y_train)\n",
        "    pred_test = mdl.predict(X_test_std)\n",
        "    accuracy_test = accuracy_score(y_test, pred_test)\n",
        "    return 1.0 - accuracy_test\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Read Dataset\n",
        "    covtype = fetch_covtype()\n",
        "    x = covtype.data\n",
        "    y = covtype.target\n",
        "    df = pd.DataFrame(x, columns = covtype.feature_names).assign(Cover_Type=y)\n",
        "    print(df)\n",
        "\n",
        "    # Cross Validation\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "    rskf = RepeatedStratifiedKFold(n_splits=4, n_repeats=5, random_state=0)\n",
        "\n",
        "    # LightGBM Parameter\n",
        "    num_round = 50\n",
        "    early_rounds = 25\n",
        "    lgb_params = {'objective': 'multiclass', 'num_class': 21,'metric': 'multi_logloss', 'seed': 0, 'verbose': 0, 'force_col_wise': 'true'}\n",
        "    results_lgb = np.array([])\n",
        "\n",
        "    # Other Machine Learning Model\n",
        "    ss = StandardScaler()\n",
        "    # pca = PCA(n_components=10)\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "    # mlr = LogisticRegression(multi_class='multinomial', random_state=0)\n",
        "    # mnb = MultinomialNB()\n",
        "    svc = svm.SVC(kernel='rbf', max_iter=50)\n",
        "    rfc = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "    results_knn = np.array([])\n",
        "    # results_mlr = np.array([])\n",
        "    # results_mnb = np.array([])\n",
        "    results_svc = np.array([])\n",
        "    results_rfc = np.array([])\n",
        "\n",
        "    for train, valid in rskf.split(x_train, y_train):\n",
        "\n",
        "      # LightGBM\n",
        "      lgb_train = lgb.Dataset(x_train[train], y_train[train], feature_name=covtype.feature_names)\n",
        "      lgb_eval = lgb.Dataset(x_train[valid], y_train[valid], feature_name=covtype.feature_names, reference=lgb_train)\n",
        "      lgb.test = lgb.Dataset(x_test, y_test)\n",
        "      lgb_evals_result = {}\n",
        "      cla_lgb = lgb.train(params=lgb_params, train_set=lgb_train, num_boost_round=num_round,\n",
        "                          valid_names=['train', 'valid'], valid_sets=[lgb_train, lgb_eval])\n",
        "      preds = cla_lgb.predict(x_test, num_iteration=cla_lgb.best_iteration)\n",
        "      y_pred_lgb = []\n",
        "      for x in preds:\n",
        "          y_pred_lgb.append(np.argmax(x))\n",
        "      result = accuracy_score(y_test, y_pred_lgb)\n",
        "      print(\"LGB\")\n",
        "      print(accuracy_score(y_test, y_pred_lgb))  # , f1_score(y_test, y_pred_lgb, average='macro'))\n",
        "      lgb.plot_importance(cla_lgb)\n",
        "      results_lgb = np.append(results_lgb, result)\n",
        "      \n",
        "      # Feature Scaling\n",
        "      x_train_std = ss.fit_transform(x_train[train])\n",
        "      x_valid_std = ss.transform(x_train[valid])\n",
        "\n",
        "      # k-Nearest Neighbor\n",
        "      knn.fit(x_train_std, y_train[train])\n",
        "      y_pred = knn.predict(x_valid_std)\n",
        "      result = accuracy_score(y_train[valid], y_pred)\n",
        "      # result = f1_score(y_train[valid], y_pred)\n",
        "      print(\"kNN:\")\n",
        "      print(result)\n",
        "      results_knn = np.append(results_knn, result)\n",
        "      '''\n",
        "      # Multinomial Logistic Regression\n",
        "      mlr.fit(x_train_std, y_train[train])\n",
        "      y_pred = mlr.predict(x_valid_std)\n",
        "      result = accuracy_score(y_train[valid], y_pred)\n",
        "      # result = f1_score(y_train[valid], y_pred)\n",
        "      print(\"MLR:\")\n",
        "      print(result)\n",
        "      results_mlr = np.append(results_mlr, result)\n",
        "\n",
        "      # Multinomial Naive Bayes\n",
        "      mnb.fit(x_train_std, y_train[train])\n",
        "      y_pred = mnb.predict(x_valid_std)\n",
        "      result = accuracy_score(y_train[valid], y_pred)\n",
        "      # result = f1_score(y_train[valid], y_pred)\n",
        "      print(\"MNB:\")\n",
        "      print(result)\n",
        "      results_mnb = np.append(results_mnb, result)\n",
        "      '''\n",
        "      # Support Vector Machine (RBF)\n",
        "      svc.fit(x_train_std, y_train[train])\n",
        "      y_pred = svc.predict(x_valid_std)\n",
        "      result = accuracy_score(y_train[valid], y_pred)\n",
        "      # result = f1_score(y_train[valid], y_pred)\n",
        "      print(\"SVC:\")\n",
        "      print(result)\n",
        "      results_svc = np.append(results_svc, result)\n",
        "\n",
        "      # Random Forest Classifier\n",
        "      rfc.fit(x_train[train], y_train[train])\n",
        "      y_pred = rfc.predict(x_train[valid])\n",
        "      result = accuracy_score(y_train[valid], y_pred)\n",
        "      # result = f1_score(y_train[valid], y_pred)\n",
        "      print(\"RFC:\")\n",
        "      print(result)\n",
        "      results_rfc = np.append(results_rfc, result)\n",
        "\n",
        "    # Output Results\n",
        "    print(\"LGB:\", np.mean(results_lgb), \"±\", np.std(results_lgb))\n",
        "    print(\"kNN:\", np.mean(results_knn), \"±\", np.std(results_knn))\n",
        "    # print(\"MLR:\", np.mean(results_mlr), \"±\", np.std(results_mlr))\n",
        "    # print(\"MNB:\", np.mean(results_mnb), \"±\", np.std(results_mnb))\n",
        "    print(\"SVC:\", np.mean(results_svc), \"±\", np.std(results_svc))\n",
        "    print(\"RFC:\", np.mean(results_rfc), \"±\", np.std(results_rfc))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQbbOidSZtH9CiOIWPHQT1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}